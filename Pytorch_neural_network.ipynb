{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng0lqz-onWbJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.1307,),(0.3081,))])"
      ],
      "metadata": {
        "id": "-rmqW6GUnz5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST('data' , train=True , download=True,transform=transform)"
      ],
      "metadata": {
        "id": "mibSFpoio79z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=True)"
      ],
      "metadata": {
        "id": "rN4kg2_vo8hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Neural(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Neural, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "        #self.fc3 = nn.Linear(10, 5)  # Add another layer with input size 10 and output size 5\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "       # x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the Neural class\n",
        "net = Neural()\n"
      ],
      "metadata": {
        "id": "VXYJnEdOq5OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(net.parameters(),lr=0.01,momentum=0.5)\n"
      ],
      "metadata": {
        "id": "wnl3gBKM0hA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=10\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_idx,(data,target) in enumerate (train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    output=net(data)\n",
        "    loss =criterion(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 100==0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmrzikNS0hgP",
        "outputId": "a83540c8-b69b-4054-dc60-5c96fda35990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.305581\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.236670\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 1.999059\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 1.530465\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.862879\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.796778\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.582807\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.750364\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.458870\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.443543\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.328688\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.758849\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.667800\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.611478\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.343648\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.507490\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.573678\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.116275\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.152983\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.350408\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.304033\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.306838\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.150433\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.176176\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.166345\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.044724\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.176988\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.118656\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.125119\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.157560\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.143985\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.090405\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.276226\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.185917\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.058969\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.134301\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.136101\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.095177\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.211115\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.126705\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.075781\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.048180\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.079818\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.134010\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.166716\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.056472\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.193492\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.172798\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.025776\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.081105\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.086932\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.099940\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.033656\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.081371\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.107847\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.025994\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.119574\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.185686\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.195189\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.072249\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.066039\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.065180\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.015047\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.019530\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.089576\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.068679\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.076210\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.065544\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.037384\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.072782\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.086682\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.017338\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.017888\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.221458\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.103190\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.209544\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.053209\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.011072\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.039815\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.024231\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.091066\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.037840\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.105561\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.104340\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.062517\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.297126\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.114316\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.052697\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.035780\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.047716\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.021506\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.065788\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.019437\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.021056\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.007852\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.037852\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.027687\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.019012\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.072951\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.070216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset=datasets.MNIST('data',train=False,download=True,transform=transform)\n",
        "test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=1000,shuffle=True)\n",
        "correct=0\n",
        "total=0\n",
        "with torch.no_grad():\n",
        "  output=net(data)\n",
        "  _,predicted=torch.max(output.data,1)\n",
        "  total+=target.size(0)\n",
        "  correct+=(predicted==target).sum().item()\n",
        "\n"
      ],
      "metadata": {
        "id": "gzDXOhJF0hyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD2Ff8lP0h9C",
        "outputId": "098914f1-6904-4274-cd98-d7dc90d32fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 100 %\n"
          ]
        }
      ]
    }
  ]
}